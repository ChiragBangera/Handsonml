{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import root_mean_squared_error, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.pipeline import  make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data[['petal length (cm)', 'petal width (cm)']].values\n",
    "y = (iris.target == 0) # setosa\n",
    "\n",
    "per_clf = Perceptron(random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "X_new = [[2, 0.5], [3, 1]]\n",
    "y_pred = per_clf.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5053326657968678\n"
     ]
    }
   ],
   "source": [
    "# sklearn implementaion\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "mlp_reg = MLPRegressor(hidden_layer_sizes=[50,50,50], random_state=42) # three hidden layers each\n",
    "pipeline = make_pipeline(StandardScaler(), mlp_reg)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_valid)\n",
    "\n",
    "rmse = root_mean_squared_error(y_valid, y_pred)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.64878217\n",
      "Iteration 2, loss = 0.62521621\n",
      "Iteration 3, loss = 0.60262438\n",
      "Iteration 4, loss = 0.58093986\n",
      "Iteration 5, loss = 0.56038341\n",
      "Iteration 6, loss = 0.54040324\n",
      "Iteration 7, loss = 0.52162517\n",
      "Iteration 8, loss = 0.50348359\n",
      "Iteration 9, loss = 0.48568728\n",
      "Iteration 10, loss = 0.46896736\n",
      "Iteration 11, loss = 0.45338472\n",
      "Iteration 12, loss = 0.43805657\n",
      "Iteration 13, loss = 0.42288916\n",
      "Iteration 14, loss = 0.40798801\n",
      "Iteration 15, loss = 0.39358182\n",
      "Iteration 16, loss = 0.37943181\n",
      "Iteration 17, loss = 0.36542432\n",
      "Iteration 18, loss = 0.35151472\n",
      "Iteration 19, loss = 0.33758809\n",
      "Iteration 20, loss = 0.32380489\n",
      "Iteration 21, loss = 0.31028353\n",
      "Iteration 22, loss = 0.29702492\n",
      "Iteration 23, loss = 0.28403963\n",
      "Iteration 24, loss = 0.27139038\n",
      "Iteration 25, loss = 0.25929616\n",
      "Iteration 26, loss = 0.24771068\n",
      "Iteration 27, loss = 0.23648726\n",
      "Iteration 28, loss = 0.22565096\n",
      "Iteration 29, loss = 0.21528325\n",
      "Iteration 30, loss = 0.20519848\n",
      "Iteration 31, loss = 0.19537750\n",
      "Iteration 32, loss = 0.18584385\n",
      "Iteration 33, loss = 0.17662578\n",
      "Iteration 34, loss = 0.16772675\n",
      "Iteration 35, loss = 0.15916960\n",
      "Iteration 36, loss = 0.15094603\n",
      "Iteration 37, loss = 0.14304146\n",
      "Iteration 38, loss = 0.13545080\n",
      "Iteration 39, loss = 0.12817956\n",
      "Iteration 40, loss = 0.12121585\n",
      "Iteration 41, loss = 0.11455117\n",
      "Iteration 42, loss = 0.10816571\n",
      "Iteration 43, loss = 0.10209302\n",
      "Iteration 44, loss = 0.09631552\n",
      "Iteration 45, loss = 0.09082857\n",
      "Iteration 46, loss = 0.08563269\n",
      "Iteration 47, loss = 0.08076236\n",
      "Iteration 48, loss = 0.07615101\n",
      "Iteration 49, loss = 0.07185593\n",
      "Iteration 50, loss = 0.06782407\n",
      "Iteration 51, loss = 0.06399942\n",
      "Iteration 52, loss = 0.06035053\n",
      "Iteration 53, loss = 0.05690233\n",
      "Iteration 54, loss = 0.05365487\n",
      "Iteration 55, loss = 0.05060737\n",
      "Iteration 56, loss = 0.04776383\n",
      "Iteration 57, loss = 0.04510079\n",
      "Iteration 58, loss = 0.04260942\n",
      "Iteration 59, loss = 0.04026994\n",
      "Iteration 60, loss = 0.03807140\n",
      "Iteration 61, loss = 0.03600469\n",
      "Iteration 62, loss = 0.03406839\n",
      "Iteration 63, loss = 0.03225248\n",
      "Iteration 64, loss = 0.03054400\n",
      "Iteration 65, loss = 0.02894582\n",
      "Iteration 66, loss = 0.02745046\n",
      "Iteration 67, loss = 0.02604975\n",
      "Iteration 68, loss = 0.02474076\n",
      "Iteration 69, loss = 0.02351462\n",
      "Iteration 70, loss = 0.02236228\n",
      "Iteration 71, loss = 0.02127968\n",
      "Iteration 72, loss = 0.02026238\n",
      "Iteration 73, loss = 0.01930657\n",
      "Iteration 74, loss = 0.01840961\n",
      "Iteration 75, loss = 0.01756686\n",
      "Iteration 76, loss = 0.01677460\n",
      "Iteration 77, loss = 0.01603160\n",
      "Iteration 78, loss = 0.01533501\n",
      "Iteration 79, loss = 0.01467980\n",
      "Iteration 80, loss = 0.01406309\n",
      "Iteration 81, loss = 0.01348226\n",
      "Iteration 82, loss = 0.01293512\n",
      "Iteration 83, loss = 0.01241946\n",
      "Iteration 84, loss = 0.01193410\n",
      "Iteration 85, loss = 0.01147773\n",
      "Iteration 86, loss = 0.01104837\n",
      "Iteration 87, loss = 0.01064489\n",
      "Iteration 88, loss = 0.01026357\n",
      "Iteration 89, loss = 0.00990367\n",
      "Iteration 90, loss = 0.00956217\n",
      "Iteration 91, loss = 0.00923869\n",
      "Iteration 92, loss = 0.00893216\n",
      "Iteration 93, loss = 0.00864049\n",
      "Iteration 94, loss = 0.00836270\n",
      "Iteration 95, loss = 0.00809806\n",
      "Iteration 96, loss = 0.00784600\n",
      "Iteration 97, loss = 0.00760568\n",
      "Iteration 98, loss = 0.00737664\n",
      "Iteration 99, loss = 0.00715868\n",
      "Iteration 100, loss = 0.00695185\n",
      "Iteration 101, loss = 0.00675427\n",
      "Iteration 102, loss = 0.00656525\n",
      "Iteration 103, loss = 0.00638492\n",
      "Iteration 104, loss = 0.00621296\n",
      "Iteration 105, loss = 0.00604875\n",
      "Iteration 106, loss = 0.00589154\n",
      "Iteration 107, loss = 0.00574094\n",
      "Iteration 108, loss = 0.00559646\n",
      "Iteration 109, loss = 0.00545794\n",
      "Iteration 110, loss = 0.00532467\n",
      "Iteration 111, loss = 0.00519635\n",
      "Iteration 112, loss = 0.00507275\n",
      "Iteration 113, loss = 0.00495364\n",
      "Iteration 114, loss = 0.00483890\n",
      "Iteration 115, loss = 0.00472843\n",
      "Iteration 116, loss = 0.00462197\n",
      "Iteration 117, loss = 0.00451937\n",
      "Iteration 118, loss = 0.00442046\n",
      "Iteration 119, loss = 0.00432499\n",
      "Iteration 120, loss = 0.00423298\n",
      "Iteration 121, loss = 0.00414394\n",
      "Iteration 122, loss = 0.00405785\n",
      "Iteration 123, loss = 0.00397460\n",
      "Iteration 124, loss = 0.00389385\n",
      "Iteration 125, loss = 0.00381563\n",
      "Iteration 126, loss = 0.00373995\n",
      "Iteration 127, loss = 0.00366653\n",
      "Iteration 128, loss = 0.00359525\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "0.0036475436091163273\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data[['petal width (cm)', 'petal length (cm)']].values\n",
    "y = (iris.target == 0)\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=[50,50,50], random_state=42, verbose=True)\n",
    "pipeline = make_pipeline(StandardScaler(), mlp_clf)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict_proba(X_valid)\n",
    "x_entropy = log_loss(y_valid, y_pred)\n",
    "print(x_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
