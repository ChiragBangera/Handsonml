{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorboard\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(32, 32, 3)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "for _ in range(20):\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(100, activation=\"swish\", kernel_initializer=\"he_normal\")\n",
    "    )\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-5)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "cifar_10 = tf.keras.datasets.cifar10.load_data()\n",
    "(x_train_full, y_train_full), (x_test, y_test) = cifar_10\n",
    "\n",
    "x_train = x_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "x_valid = x_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=20, restore_best_weights=True\n",
    ")\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"my_cifar_10_model.keras\", save_best_only=True\n",
    ")\n",
    "run_index = 1  # increment everytime you train the model\n",
    "run_logdir = Path() / \"my_cifar10_logs\" / f\"run_{run_index}:03d\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-237049eb18860ee3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-237049eb18860ee3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_cifar10_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.1256 - loss: 18.9208 - val_accuracy: 0.1952 - val_loss: 2.2330\n",
      "Epoch 2/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2080 - loss: 2.1659 - val_accuracy: 0.2534 - val_loss: 2.0229\n",
      "Epoch 3/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2536 - loss: 2.0305 - val_accuracy: 0.2786 - val_loss: 1.9452\n",
      "Epoch 4/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2804 - loss: 1.9398 - val_accuracy: 0.3114 - val_loss: 1.8850\n",
      "Epoch 5/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3117 - loss: 1.8857 - val_accuracy: 0.3158 - val_loss: 1.9149\n",
      "Epoch 6/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3394 - loss: 1.8182 - val_accuracy: 0.3498 - val_loss: 1.7753\n",
      "Epoch 7/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3546 - loss: 1.7578 - val_accuracy: 0.3724 - val_loss: 1.7650\n",
      "Epoch 8/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3780 - loss: 1.7092 - val_accuracy: 0.3664 - val_loss: 1.7438\n",
      "Epoch 9/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3944 - loss: 1.6809 - val_accuracy: 0.3820 - val_loss: 1.6879\n",
      "Epoch 10/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3970 - loss: 1.6618 - val_accuracy: 0.3960 - val_loss: 1.6734\n",
      "Epoch 11/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4135 - loss: 1.6263 - val_accuracy: 0.4148 - val_loss: 1.6276\n",
      "Epoch 12/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4241 - loss: 1.6086 - val_accuracy: 0.4138 - val_loss: 1.6213\n",
      "Epoch 13/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4281 - loss: 1.5900 - val_accuracy: 0.4146 - val_loss: 1.6234\n",
      "Epoch 14/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4324 - loss: 1.5688 - val_accuracy: 0.4210 - val_loss: 1.6165\n",
      "Epoch 15/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4474 - loss: 1.5417 - val_accuracy: 0.4118 - val_loss: 1.6123\n",
      "Epoch 16/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4477 - loss: 1.5376 - val_accuracy: 0.4318 - val_loss: 1.5867\n",
      "Epoch 17/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4544 - loss: 1.5147 - val_accuracy: 0.4398 - val_loss: 1.5878\n",
      "Epoch 18/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4573 - loss: 1.5010 - val_accuracy: 0.4352 - val_loss: 1.5704\n",
      "Epoch 19/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4592 - loss: 1.4963 - val_accuracy: 0.4262 - val_loss: 1.5952\n",
      "Epoch 20/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4668 - loss: 1.4845 - val_accuracy: 0.4406 - val_loss: 1.5705\n",
      "Epoch 21/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4693 - loss: 1.4645 - val_accuracy: 0.4364 - val_loss: 1.5680\n",
      "Epoch 22/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4778 - loss: 1.4513 - val_accuracy: 0.4454 - val_loss: 1.5614\n",
      "Epoch 23/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4791 - loss: 1.4555 - val_accuracy: 0.4550 - val_loss: 1.5458\n",
      "Epoch 24/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4820 - loss: 1.4339 - val_accuracy: 0.4550 - val_loss: 1.5303\n",
      "Epoch 25/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4891 - loss: 1.4170 - val_accuracy: 0.4468 - val_loss: 1.5696\n",
      "Epoch 26/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4867 - loss: 1.4198 - val_accuracy: 0.4462 - val_loss: 1.5504\n",
      "Epoch 27/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4915 - loss: 1.4135 - val_accuracy: 0.4472 - val_loss: 1.5647\n",
      "Epoch 28/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5017 - loss: 1.3879 - val_accuracy: 0.4176 - val_loss: 1.6153\n",
      "Epoch 29/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5014 - loss: 1.3912 - val_accuracy: 0.4588 - val_loss: 1.5438\n",
      "Epoch 30/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5058 - loss: 1.3737 - val_accuracy: 0.4610 - val_loss: 1.5236\n",
      "Epoch 31/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5052 - loss: 1.3703 - val_accuracy: 0.4624 - val_loss: 1.5246\n",
      "Epoch 32/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5112 - loss: 1.3605 - val_accuracy: 0.4500 - val_loss: 1.5565\n",
      "Epoch 33/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5130 - loss: 1.3528 - val_accuracy: 0.4372 - val_loss: 1.6418\n",
      "Epoch 34/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5154 - loss: 1.3438 - val_accuracy: 0.4672 - val_loss: 1.5135\n",
      "Epoch 35/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5261 - loss: 1.3253 - val_accuracy: 0.4532 - val_loss: 1.5400\n",
      "Epoch 36/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5189 - loss: 1.3302 - val_accuracy: 0.4644 - val_loss: 1.5310\n",
      "Epoch 37/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5251 - loss: 1.3245 - val_accuracy: 0.4560 - val_loss: 1.5518\n",
      "Epoch 38/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5303 - loss: 1.3164 - val_accuracy: 0.4738 - val_loss: 1.5131\n",
      "Epoch 39/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5308 - loss: 1.3031 - val_accuracy: 0.4684 - val_loss: 1.5267\n",
      "Epoch 40/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5320 - loss: 1.2964 - val_accuracy: 0.4620 - val_loss: 1.5476\n",
      "Epoch 41/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5380 - loss: 1.2824 - val_accuracy: 0.4628 - val_loss: 1.5440\n",
      "Epoch 42/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5417 - loss: 1.2835 - val_accuracy: 0.4650 - val_loss: 1.5262\n",
      "Epoch 43/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5431 - loss: 1.2772 - val_accuracy: 0.4520 - val_loss: 1.5689\n",
      "Epoch 44/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5455 - loss: 1.2700 - val_accuracy: 0.4656 - val_loss: 1.5440\n",
      "Epoch 45/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5468 - loss: 1.2613 - val_accuracy: 0.4564 - val_loss: 1.5607\n",
      "Epoch 46/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5536 - loss: 1.2514 - val_accuracy: 0.4724 - val_loss: 1.5334\n",
      "Epoch 47/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5513 - loss: 1.2458 - val_accuracy: 0.4534 - val_loss: 1.5546\n",
      "Epoch 48/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5509 - loss: 1.2485 - val_accuracy: 0.4786 - val_loss: 1.5248\n",
      "Epoch 49/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5558 - loss: 1.2332 - val_accuracy: 0.4522 - val_loss: 1.5711\n",
      "Epoch 50/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5599 - loss: 1.2297 - val_accuracy: 0.4718 - val_loss: 1.5525\n",
      "Epoch 51/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5628 - loss: 1.2208 - val_accuracy: 0.4640 - val_loss: 1.5675\n",
      "Epoch 52/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5652 - loss: 1.2158 - val_accuracy: 0.4666 - val_loss: 1.5499\n",
      "Epoch 53/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5691 - loss: 1.2038 - val_accuracy: 0.4634 - val_loss: 1.5659\n",
      "Epoch 54/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5723 - loss: 1.2033 - val_accuracy: 0.4646 - val_loss: 1.5929\n",
      "Epoch 55/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5684 - loss: 1.1969 - val_accuracy: 0.4654 - val_loss: 1.5506\n",
      "Epoch 56/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5782 - loss: 1.1885 - val_accuracy: 0.4598 - val_loss: 1.5722\n",
      "Epoch 57/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5712 - loss: 1.1870 - val_accuracy: 0.4614 - val_loss: 1.5854\n",
      "Epoch 58/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5851 - loss: 1.1644 - val_accuracy: 0.4614 - val_loss: 1.5635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x316824bf0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model fitting\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4788 - loss: 1.5196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5131490230560303, 0.47380000352859497]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.1979 - loss: 2.1950 - val_accuracy: 0.3038 - val_loss: 1.9209\n",
      "Epoch 2/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.3553 - loss: 1.7968 - val_accuracy: 0.3276 - val_loss: 1.8665\n",
      "Epoch 3/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.3990 - loss: 1.6839 - val_accuracy: 0.3404 - val_loss: 1.9136\n",
      "Epoch 4/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4212 - loss: 1.6184 - val_accuracy: 0.3880 - val_loss: 1.7043\n",
      "Epoch 5/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4427 - loss: 1.5656 - val_accuracy: 0.3902 - val_loss: 1.7118\n",
      "Epoch 6/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4626 - loss: 1.5138 - val_accuracy: 0.3938 - val_loss: 1.6807\n",
      "Epoch 7/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4789 - loss: 1.4674 - val_accuracy: 0.4458 - val_loss: 1.5569\n",
      "Epoch 8/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4955 - loss: 1.4216 - val_accuracy: 0.4150 - val_loss: 1.6887\n",
      "Epoch 9/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5154 - loss: 1.3814 - val_accuracy: 0.4544 - val_loss: 1.5130\n",
      "Epoch 10/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5169 - loss: 1.3554 - val_accuracy: 0.4316 - val_loss: 1.6493\n",
      "Epoch 11/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5350 - loss: 1.3170 - val_accuracy: 0.4704 - val_loss: 1.5050\n",
      "Epoch 12/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5442 - loss: 1.2887 - val_accuracy: 0.4632 - val_loss: 1.5208\n",
      "Epoch 13/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5485 - loss: 1.2686 - val_accuracy: 0.4908 - val_loss: 1.4465\n",
      "Epoch 14/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5593 - loss: 1.2492 - val_accuracy: 0.4496 - val_loss: 1.5823\n",
      "Epoch 15/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5690 - loss: 1.2204 - val_accuracy: 0.4892 - val_loss: 1.4631\n",
      "Epoch 16/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5705 - loss: 1.2150 - val_accuracy: 0.3730 - val_loss: 2.1210\n",
      "Epoch 17/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5821 - loss: 1.1946 - val_accuracy: 0.4484 - val_loss: 1.5847\n",
      "Epoch 18/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5884 - loss: 1.1719 - val_accuracy: 0.4888 - val_loss: 1.4685\n",
      "Epoch 19/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5988 - loss: 1.1416 - val_accuracy: 0.4736 - val_loss: 1.5773\n",
      "Epoch 20/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6039 - loss: 1.1304 - val_accuracy: 0.4630 - val_loss: 1.5997\n",
      "Epoch 21/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6107 - loss: 1.1092 - val_accuracy: 0.4636 - val_loss: 1.5809\n",
      "Epoch 22/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6148 - loss: 1.1030 - val_accuracy: 0.5006 - val_loss: 1.4343\n",
      "Epoch 23/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.6171 - loss: 1.0842 - val_accuracy: 0.4120 - val_loss: 1.9027\n",
      "Epoch 24/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6304 - loss: 1.0594 - val_accuracy: 0.4910 - val_loss: 1.4974\n",
      "Epoch 25/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6326 - loss: 1.0452 - val_accuracy: 0.4838 - val_loss: 1.5511\n",
      "Epoch 26/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6372 - loss: 1.0407 - val_accuracy: 0.5088 - val_loss: 1.5024\n",
      "Epoch 27/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.6355 - loss: 1.0348 - val_accuracy: 0.4936 - val_loss: 1.4967\n",
      "Epoch 28/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6428 - loss: 1.0096 - val_accuracy: 0.5042 - val_loss: 1.4471\n",
      "Epoch 29/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6481 - loss: 0.9975 - val_accuracy: 0.4636 - val_loss: 1.6349\n",
      "Epoch 30/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.6524 - loss: 0.9895 - val_accuracy: 0.5040 - val_loss: 1.4834\n",
      "Epoch 31/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.6585 - loss: 0.9673 - val_accuracy: 0.4948 - val_loss: 1.5418\n",
      "Epoch 32/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.6554 - loss: 0.9773 - val_accuracy: 0.5010 - val_loss: 1.5210\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5014 - loss: 1.4185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.434305191040039, 0.5005999803543091]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding batch normalization\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(32, 32, 3)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "for _ in range(20):\n",
    "    model.add(tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation(\"swish\"))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# callbacks\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=10, restore_best_weights=True\n",
    ")\n",
    "run_index = 1  # increment every time the model is run\n",
    "run_logdir = Path() / \"my_cifar10_logs_bn\" / f\"run_{run_index:03d}\"\n",
    "tensorboard_cb_bn = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb_bn]\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "model.evaluate(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.2764 - loss: 2.0251 - val_accuracy: 0.3864 - val_loss: 1.7309\n",
      "Epoch 2/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.3910 - loss: 1.7166 - val_accuracy: 0.4072 - val_loss: 1.6704\n",
      "Epoch 3/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.4296 - loss: 1.6241 - val_accuracy: 0.4288 - val_loss: 1.6412\n",
      "Epoch 4/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.4579 - loss: 1.5462 - val_accuracy: 0.4354 - val_loss: 1.6265\n",
      "Epoch 5/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.4774 - loss: 1.4901 - val_accuracy: 0.4556 - val_loss: 1.5571\n",
      "Epoch 6/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.4841 - loss: 1.4629 - val_accuracy: 0.4486 - val_loss: 1.5862\n",
      "Epoch 7/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5070 - loss: 1.3987 - val_accuracy: 0.4714 - val_loss: 1.5464\n",
      "Epoch 8/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5259 - loss: 1.3562 - val_accuracy: 0.4624 - val_loss: 1.5471\n",
      "Epoch 9/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5358 - loss: 1.3270 - val_accuracy: 0.4810 - val_loss: 1.5313\n",
      "Epoch 10/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5534 - loss: 1.2822 - val_accuracy: 0.4896 - val_loss: 1.5319\n",
      "Epoch 11/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5618 - loss: 1.2624 - val_accuracy: 0.4964 - val_loss: 1.4851\n",
      "Epoch 12/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5771 - loss: 1.2261 - val_accuracy: 0.4990 - val_loss: 1.4942\n",
      "Epoch 13/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5852 - loss: 1.2053 - val_accuracy: 0.5000 - val_loss: 1.5203\n",
      "Epoch 14/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5952 - loss: 1.1752 - val_accuracy: 0.4808 - val_loss: 1.5282\n",
      "Epoch 15/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6017 - loss: 1.1517 - val_accuracy: 0.4934 - val_loss: 1.5020\n",
      "Epoch 16/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6083 - loss: 1.1350 - val_accuracy: 0.5100 - val_loss: 1.4940\n",
      "Epoch 17/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6207 - loss: 1.1074 - val_accuracy: 0.4988 - val_loss: 1.5654\n",
      "Epoch 18/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6253 - loss: 1.0962 - val_accuracy: 0.4972 - val_loss: 1.5558\n",
      "Epoch 19/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6340 - loss: 1.0680 - val_accuracy: 0.5092 - val_loss: 1.5270\n",
      "Epoch 20/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6408 - loss: 1.0455 - val_accuracy: 0.4968 - val_loss: 1.5601\n",
      "Epoch 21/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6489 - loss: 1.0294 - val_accuracy: 0.5130 - val_loss: 1.5526\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5071 - loss: 1.4705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4850661754608154, 0.49639999866485596]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bn with selu and le cun initializer\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(32, 32, 3)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "for _ in range(20):\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(100, kernel_initializer=\"lecun_normal\", activation=\"selu\")\n",
    "    )\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=7e-4)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"my_cifar10_selu_model.keras\", save_best_only=True\n",
    ")\n",
    "\n",
    "# callbacks\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=20, restore_best_weights=True\n",
    ")\n",
    "\n",
    "run_index = 1  # increment every time the model is run\n",
    "run_logdir = Path() / \"my_cifar10_logs\" / f\"run_selu{run_index:03d}\"\n",
    "tensorboard_cb_bn = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb_bn]\n",
    "\n",
    "\n",
    "x_means = x_train.mean(axis=0)\n",
    "x_stds = x_train.std(axis=0)\n",
    "x_train_scaled = (x_train - x_means) / x_stds\n",
    "x_valid_scaled = (x_valid - x_means) / x_stds\n",
    "x_test_scaled = (x_test - x_means) / x_stds\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    x_train_scaled,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(x_valid_scaled, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "model.evaluate(x_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.2784 - loss: 2.0520 - val_accuracy: 0.3952 - val_loss: 1.7297\n",
      "Epoch 2/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.3967 - loss: 1.7029 - val_accuracy: 0.4302 - val_loss: 1.6768\n",
      "Epoch 3/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.4396 - loss: 1.5975 - val_accuracy: 0.4548 - val_loss: 1.5967\n",
      "Epoch 4/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.4658 - loss: 1.5258 - val_accuracy: 0.4576 - val_loss: 1.6492\n",
      "Epoch 5/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.4866 - loss: 1.4720 - val_accuracy: 0.4728 - val_loss: 1.6005\n",
      "Epoch 6/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5073 - loss: 1.4186 - val_accuracy: 0.4662 - val_loss: 1.6430\n",
      "Epoch 7/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5236 - loss: 1.3788 - val_accuracy: 0.4822 - val_loss: 1.6185\n",
      "Epoch 8/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5359 - loss: 1.3398 - val_accuracy: 0.4834 - val_loss: 1.6093\n",
      "Epoch 9/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5544 - loss: 1.3001 - val_accuracy: 0.4900 - val_loss: 1.6115\n",
      "Epoch 10/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5705 - loss: 1.2610 - val_accuracy: 0.4904 - val_loss: 1.6498\n",
      "Epoch 11/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5779 - loss: 1.2324 - val_accuracy: 0.4930 - val_loss: 1.5756\n",
      "Epoch 12/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5839 - loss: 1.2058 - val_accuracy: 0.4986 - val_loss: 1.6713\n",
      "Epoch 13/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5978 - loss: 1.1792 - val_accuracy: 0.4916 - val_loss: 1.6887\n",
      "Epoch 14/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6105 - loss: 1.1495 - val_accuracy: 0.4940 - val_loss: 1.6409\n",
      "Epoch 15/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6230 - loss: 1.1195 - val_accuracy: 0.4962 - val_loss: 1.6521\n",
      "Epoch 16/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6226 - loss: 1.1056 - val_accuracy: 0.4986 - val_loss: 1.6566\n",
      "Epoch 17/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6330 - loss: 1.0788 - val_accuracy: 0.4880 - val_loss: 1.6784\n",
      "Epoch 18/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6429 - loss: 1.0561 - val_accuracy: 0.4874 - val_loss: 1.7416\n",
      "Epoch 19/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6469 - loss: 1.0448 - val_accuracy: 0.4910 - val_loss: 1.7310\n",
      "Epoch 20/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6536 - loss: 1.0236 - val_accuracy: 0.4926 - val_loss: 1.7598\n",
      "Epoch 21/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6545 - loss: 1.0132 - val_accuracy: 0.4860 - val_loss: 1.7814\n",
      "Epoch 22/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6600 - loss: 1.0024 - val_accuracy: 0.4840 - val_loss: 1.7336\n",
      "Epoch 23/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6735 - loss: 0.9656 - val_accuracy: 0.4944 - val_loss: 1.7571\n",
      "Epoch 24/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6742 - loss: 0.9677 - val_accuracy: 0.4896 - val_loss: 1.8430\n",
      "Epoch 25/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6842 - loss: 0.9487 - val_accuracy: 0.4972 - val_loss: 1.7460\n",
      "Epoch 26/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6820 - loss: 0.9397 - val_accuracy: 0.4970 - val_loss: 1.8800\n",
      "Epoch 27/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6868 - loss: 0.9197 - val_accuracy: 0.4992 - val_loss: 1.8176\n",
      "Epoch 28/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6923 - loss: 0.9144 - val_accuracy: 0.4914 - val_loss: 1.8571\n",
      "Epoch 29/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6929 - loss: 0.9070 - val_accuracy: 0.4860 - val_loss: 1.8617\n",
      "Epoch 30/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7048 - loss: 0.8800 - val_accuracy: 0.4970 - val_loss: 1.8633\n",
      "Epoch 31/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7102 - loss: 0.8740 - val_accuracy: 0.4862 - val_loss: 2.0493\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4938 - loss: 1.5755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5756477117538452, 0.49300000071525574]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding dropout in layers using mc dropout\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(32, 32, 3)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "for _ in range(20):\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(100, kernel_initializer=\"lecun_normal\", activation=\"selu\")\n",
    "    )\n",
    "\n",
    "model.add(tf.keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"my_cifar10_alpha_dropout_model.keras\", save_best_only=True\n",
    ")\n",
    "\n",
    "# callbacks\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=20, restore_best_weights=True\n",
    ")\n",
    "\n",
    "run_index = 2  # increment every time the model is run\n",
    "run_logdir = Path() / \"my_cifar10_logs\" / f\"run_alpha_dropout_{run_index:03d}\"\n",
    "tensorboard_cb_bn = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb_bn]\n",
    "\n",
    "\n",
    "x_means = x_train.mean(axis=0)\n",
    "x_stds = x_train.std(axis=0)\n",
    "x_train_scaled = (x_train - x_means) / x_stds\n",
    "x_valid_scaled = (x_valid - x_means) / x_stds\n",
    "x_test_scaled = (x_test - x_means) / x_stds\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    x_train_scaled,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(x_valid_scaled, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "model.evaluate(x_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using mc dropout\n",
    "\n",
    "\n",
    "class MCAlphaDropout(tf.keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = tf.keras.Sequential(\n",
    "    [\n",
    "        (\n",
    "            MCAlphaDropout(layer.rate)\n",
    "            if isinstance(layer, tf.keras.layers.AlphaDropout)\n",
    "            else layer\n",
    "        )\n",
    "        for layer in model.layers\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_dropout_predict_probas(mc_model, x, n_samples=10):\n",
    "    y_probas = [mc_model.predict(x) for sample in range(n_samples)]\n",
    "    return np.mean(y_probas, axis=0)\n",
    "\n",
    "\n",
    "def mc_dropout_predict_classes(mc_model, x, n_samples=10):\n",
    "    y_probas = mc_dropout_predict_probas(mc_model, x, n_samples)\n",
    "    return y_probas.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4916"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "y_preds = mc_dropout_predict_classes(mc_model, x_valid_scaled)\n",
    "accuracy = (y_preds == y_valid[:, 0]).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retaining a model using 1cycle scheduling\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(32, 32, 3)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "for _ in range(20):\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(100, kernel_initializer=\"lecun_normal\", activation=\"selu\")\n",
    "    )\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD()\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
