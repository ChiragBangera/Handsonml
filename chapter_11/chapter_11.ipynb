{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying selu sctivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neutal net with 100 hidden layers\n",
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(28, 28)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "for layer in range(100):\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\")\n",
    "    )\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]\n",
    "X_train, X_valid, X_test = X_train / 255, X_valid / 255, X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing the pixels\n",
    "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
    "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
    "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
    "X_test_scaled = (X_test - pixel_means) / pixel_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.4129 - loss: 1.5114 - val_accuracy: 0.6950 - val_loss: 0.8191\n",
      "Epoch 2/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.7051 - loss: 0.8133 - val_accuracy: 0.7470 - val_loss: 0.7024\n",
      "Epoch 3/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.7471 - loss: 0.6966 - val_accuracy: 0.7728 - val_loss: 0.6358\n",
      "Epoch 4/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.7758 - loss: 0.6123 - val_accuracy: 0.7812 - val_loss: 0.6117\n",
      "Epoch 5/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.7831 - loss: 0.5950 - val_accuracy: 0.7904 - val_loss: 0.5591\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_scaled, y_train, epochs=5, validation_data=[X_valid_scaled, y_valid]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Normalization\n",
    "dense_layer = partial(\n",
    "    tf.keras.layers.Dense, activation=\"relu\", kernel_initializer=\"he_normal\"\n",
    ")\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Input(shape=(28, 28)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        dense_layer(300, use_bias=False),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation(\"relu\"),\n",
    "        dense_layer(100, use_bias=False),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation(\"relu\"),\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gamma', True),\n",
       " ('beta', True),\n",
       " ('moving_mean', False),\n",
       " ('moving_variance', False)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(var.name, var.trainable) for var in model.layers[2].variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7237 - loss: 0.8530 - val_accuracy: 0.8490 - val_loss: 0.4218\n",
      "Epoch 2/2\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8510 - loss: 0.4339 - val_accuracy: 0.8718 - val_loss: 0.3761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x325e72bd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model.fit(X_train_scaled, y_train, epochs=2, validation_data=[X_valid_scaled, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8722 - loss: 0.3630 - val_accuracy: 0.8746 - val_loss: 0.3578\n",
      "Epoch 2/2\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8894 - loss: 0.3170 - val_accuracy: 0.8760 - val_loss: 0.3521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x325b7ac90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model.fit(X_train_scaled, y_train, epochs=2, validation_data=[X_valid_scaled, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Clipping\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(clipvalue=1.0)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(clipnorm=1.0)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 0.5237 - loss: 1.5058 - val_accuracy: 0.7824 - val_loss: 0.7006\n",
      "Epoch 2/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - accuracy: 0.7894 - loss: 0.6520 - val_accuracy: 0.8406 - val_loss: 0.5147\n",
      "Epoch 3/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 0.8404 - loss: 0.5018 - val_accuracy: 0.8586 - val_loss: 0.4380\n",
      "Epoch 4/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 861us/step - accuracy: 0.8619 - loss: 0.4321 - val_accuracy: 0.8661 - val_loss: 0.3957\n",
      "Epoch 5/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 784us/step - accuracy: 0.8721 - loss: 0.3914 - val_accuracy: 0.8737 - val_loss: 0.3694\n",
      "Epoch 6/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761us/step - accuracy: 0.8789 - loss: 0.3647 - val_accuracy: 0.8772 - val_loss: 0.3511\n",
      "Epoch 7/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 769us/step - accuracy: 0.8839 - loss: 0.3455 - val_accuracy: 0.8802 - val_loss: 0.3376\n",
      "Epoch 8/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 876us/step - accuracy: 0.8873 - loss: 0.3309 - val_accuracy: 0.8834 - val_loss: 0.3272\n",
      "Epoch 9/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 926us/step - accuracy: 0.8917 - loss: 0.3194 - val_accuracy: 0.8862 - val_loss: 0.3188\n",
      "Epoch 10/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 897us/step - accuracy: 0.8942 - loss: 0.3100 - val_accuracy: 0.8877 - val_loss: 0.3119\n",
      "Epoch 11/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 0.8963 - loss: 0.3021 - val_accuracy: 0.8899 - val_loss: 0.3058\n",
      "Epoch 12/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 757us/step - accuracy: 0.8996 - loss: 0.2952 - val_accuracy: 0.8917 - val_loss: 0.3005\n",
      "Epoch 13/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - accuracy: 0.9020 - loss: 0.2892 - val_accuracy: 0.8932 - val_loss: 0.2958\n",
      "Epoch 14/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763us/step - accuracy: 0.9038 - loss: 0.2837 - val_accuracy: 0.8940 - val_loss: 0.2916\n",
      "Epoch 15/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 749us/step - accuracy: 0.9057 - loss: 0.2788 - val_accuracy: 0.8957 - val_loss: 0.2878\n",
      "Epoch 16/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - accuracy: 0.9068 - loss: 0.2744 - val_accuracy: 0.8972 - val_loss: 0.2844\n",
      "Epoch 17/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 804us/step - accuracy: 0.9084 - loss: 0.2703 - val_accuracy: 0.8980 - val_loss: 0.2810\n",
      "Epoch 18/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.9100 - loss: 0.2664 - val_accuracy: 0.9002 - val_loss: 0.2780\n",
      "Epoch 19/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - accuracy: 0.9109 - loss: 0.2629 - val_accuracy: 0.9017 - val_loss: 0.2753\n",
      "Epoch 20/20\n",
      "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 771us/step - accuracy: 0.9119 - loss: 0.2595 - val_accuracy: 0.9042 - val_loss: 0.2727\n"
     ]
    }
   ],
   "source": [
    "# Reusing pretrained layers\n",
    "pos_class_id = class_names.index(\"Pullover\")\n",
    "neg_class_id = class_names.index(\"T-shirt/top\")\n",
    "\n",
    "\n",
    "def split_dataset(X, y):\n",
    "    y_for_B = (y == pos_class_id) | (y == neg_class_id)\n",
    "    y_A = y[~y_for_B]\n",
    "    y_B = (y[y_for_B] == pos_class_id).astype(np.float32)\n",
    "    old_class_ids = list(set(range(10)) - set([neg_class_id, pos_class_id]))\n",
    "    for old_class_id, new_class_id in zip(old_class_ids, range(8)):\n",
    "        y_A[y_A == old_class_id] = new_class_id  # reorder class ids for A\n",
    "    return ((X[~y_for_B], y_A), (X[y_for_B], y_B))\n",
    "\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model_A = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Input(shape=(28, 28)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        dense_layer(100),\n",
    "        dense_layer(100),\n",
    "        dense_layer(100),\n",
    "        tf.keras.layers.Dense(8, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_A.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model_A.fit(\n",
    "    X_train_A, y_train_A, epochs=20, validation_data=[X_valid_A, y_valid_A]\n",
    ")\n",
    "model_A.save(\"my_model_a.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4301 - loss: 1.2276 - val_accuracy: 0.4847 - val_loss: 0.9876\n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4301 - loss: 1.0418 - val_accuracy: 0.4847 - val_loss: 0.8724\n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4301 - loss: 0.9150 - val_accuracy: 0.4847 - val_loss: 0.7956\n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4301 - loss: 0.8291 - val_accuracy: 0.4847 - val_loss: 0.7418\n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4301 - loss: 0.7681 - val_accuracy: 0.4857 - val_loss: 0.7032\n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4337 - loss: 0.7235 - val_accuracy: 0.4876 - val_loss: 0.6753\n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4337 - loss: 0.6909 - val_accuracy: 0.4985 - val_loss: 0.6542\n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4547 - loss: 0.6659 - val_accuracy: 0.5697 - val_loss: 0.6372\n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5608 - loss: 0.6453 - val_accuracy: 0.6667 - val_loss: 0.6228\n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6571 - loss: 0.6280 - val_accuracy: 0.7181 - val_loss: 0.6102\n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7140 - loss: 0.6129 - val_accuracy: 0.7794 - val_loss: 0.5990\n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7413 - loss: 0.5994 - val_accuracy: 0.8121 - val_loss: 0.5886\n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7976 - loss: 0.5870 - val_accuracy: 0.8338 - val_loss: 0.5787\n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8407 - loss: 0.5754 - val_accuracy: 0.8516 - val_loss: 0.5692\n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8692 - loss: 0.5644 - val_accuracy: 0.8684 - val_loss: 0.5601\n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8775 - loss: 0.5541 - val_accuracy: 0.8734 - val_loss: 0.5513\n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8811 - loss: 0.5443 - val_accuracy: 0.8823 - val_loss: 0.5428\n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8917 - loss: 0.5349 - val_accuracy: 0.8882 - val_loss: 0.5344\n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9055 - loss: 0.5257 - val_accuracy: 0.8952 - val_loss: 0.5262\n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9055 - loss: 0.5169 - val_accuracy: 0.8981 - val_loss: 0.5181\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.8919 - loss: 0.5182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5190897583961487, 0.8964999914169312]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating model B\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "model_B = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Input(shape=(28, 28)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        dense_layer(100),\n",
    "        dense_layer(100),\n",
    "        dense_layer(100),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model_B.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model_B.fit(\n",
    "    X_train_B, y_train_B, epochs=20, validation_data=[X_valid_B, y_valid_B]\n",
    ")\n",
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = tf.keras.models.load_model(\"my_model_a.keras\")\n",
    "model_B_on_A = tf.keras.Sequential(model_A.layers[:-1])  # unitl the last layer\n",
    "model_B_on_A.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# note that model_B_on_A andModel_A actually share layers now, so when we train one, it will update both models\n",
    "# If we want to avoid that, we need to build model_B_on_A on top of clone of model_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model_A_clone = tf.keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5757 - loss: 1.0715 - val_accuracy: 0.5232 - val_loss: 0.7999\n",
      "Epoch 2/4\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5444 - loss: 0.7284 - val_accuracy: 0.5589 - val_loss: 0.7306\n",
      "Epoch 3/4\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6016 - loss: 0.6939 - val_accuracy: 0.5668 - val_loss: 0.7151\n",
      "Epoch 4/4\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6054 - loss: 0.6826 - val_accuracy: 0.5875 - val_loss: 0.7011\n",
      "Epoch 1/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6519 - loss: 0.6589 - val_accuracy: 0.6677 - val_loss: 0.6487\n",
      "Epoch 2/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6918 - loss: 0.6073 - val_accuracy: 0.7211 - val_loss: 0.5977\n",
      "Epoch 3/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7445 - loss: 0.5572 - val_accuracy: 0.7626 - val_loss: 0.5553\n",
      "Epoch 4/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8108 - loss: 0.5157 - val_accuracy: 0.8002 - val_loss: 0.5201\n",
      "Epoch 5/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8558 - loss: 0.4809 - val_accuracy: 0.8338 - val_loss: 0.4900\n",
      "Epoch 6/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8693 - loss: 0.4513 - val_accuracy: 0.8497 - val_loss: 0.4639\n",
      "Epoch 7/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8812 - loss: 0.4256 - val_accuracy: 0.8655 - val_loss: 0.4415\n",
      "Epoch 8/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9017 - loss: 0.4034 - val_accuracy: 0.8764 - val_loss: 0.4216\n",
      "Epoch 9/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9036 - loss: 0.3838 - val_accuracy: 0.8853 - val_loss: 0.4042\n",
      "Epoch 10/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9124 - loss: 0.3663 - val_accuracy: 0.8971 - val_loss: 0.3888\n",
      "Epoch 11/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9232 - loss: 0.3508 - val_accuracy: 0.9050 - val_loss: 0.3751\n",
      "Epoch 12/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9232 - loss: 0.3370 - val_accuracy: 0.9080 - val_loss: 0.3628\n",
      "Epoch 13/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9232 - loss: 0.3247 - val_accuracy: 0.9110 - val_loss: 0.3517\n",
      "Epoch 14/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9353 - loss: 0.3135 - val_accuracy: 0.9130 - val_loss: 0.3417\n",
      "Epoch 15/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9353 - loss: 0.3034 - val_accuracy: 0.9169 - val_loss: 0.3326\n",
      "Epoch 16/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9353 - loss: 0.2942 - val_accuracy: 0.9169 - val_loss: 0.3243\n"
     ]
    }
   ],
   "source": [
    "model_B_on_A = tf.keras.Sequential(model_A_clone.layers[:-1])\n",
    "model_B_on_A.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# not training the/updating the weights that were taken from the previous model_A\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "model_B_on_A.compile(\n",
    "    loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model_B_on_A.fit(\n",
    "    X_train_B, y_train_B, epochs=4, validation_data=(X_valid_B, y_valid_B)\n",
    ")\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "model_B_on_A.compile(\n",
    "    loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model_B_on_A.fit(\n",
    "    X_train_B, y_train_B, epochs=16, validation_data=(X_valid_B, y_valid_B)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.9027 - loss: 0.3320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33885955810546875, 0.902999997138977]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 941us/step - accuracy: 0.6627 - loss: 0.9948 - val_accuracy: 0.8158 - val_loss: 0.5080\n",
      "Epoch 2/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - accuracy: 0.8293 - loss: 0.4897 - val_accuracy: 0.8328 - val_loss: 0.4599\n",
      "Epoch 3/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - accuracy: 0.8478 - loss: 0.4342 - val_accuracy: 0.8434 - val_loss: 0.4310\n",
      "Epoch 4/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824us/step - accuracy: 0.8575 - loss: 0.4024 - val_accuracy: 0.8518 - val_loss: 0.4086\n",
      "Epoch 5/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 790us/step - accuracy: 0.8663 - loss: 0.3799 - val_accuracy: 0.8566 - val_loss: 0.3913\n",
      "Epoch 6/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 813us/step - accuracy: 0.8712 - loss: 0.3619 - val_accuracy: 0.8616 - val_loss: 0.3806\n",
      "Epoch 7/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 813us/step - accuracy: 0.8763 - loss: 0.3478 - val_accuracy: 0.8642 - val_loss: 0.3747\n",
      "Epoch 8/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 794us/step - accuracy: 0.8810 - loss: 0.3357 - val_accuracy: 0.8646 - val_loss: 0.3682\n",
      "Epoch 9/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - accuracy: 0.8855 - loss: 0.3248 - val_accuracy: 0.8666 - val_loss: 0.3629\n",
      "Epoch 10/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 819us/step - accuracy: 0.8888 - loss: 0.3153 - val_accuracy: 0.8668 - val_loss: 0.3628\n"
     ]
    }
   ],
   "source": [
    "# Faster Optimizers\n",
    "# Momentum OPtimizer\n",
    "\n",
    "\n",
    "def build_model(seed=42):\n",
    "    tf.random.set_seed(seed)\n",
    "    return tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Input(shape=(28, 28)),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(\n",
    "                100, activation=\"relu\", kernel_initializer=\"he_normal\"\n",
    "            ),\n",
    "            tf.keras.layers.Dense(\n",
    "                100, activation=\"relu\", kernel_initializer=\"he_normal\"\n",
    "            ),\n",
    "            tf.keras.layers.Dense(\n",
    "                100, activation=\"relu\", kernel_initializer=\"he_normal\"\n",
    "            ),\n",
    "            tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def build_and_train_model(optimizer):\n",
    "    model = build_model()\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer=optimizer,\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
    "history_sgd = build_and_train_model(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 919us/step - accuracy: 0.6761 - loss: 0.9837 - val_accuracy: 0.8208 - val_loss: 0.4970\n",
      "Epoch 2/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 0.8312 - loss: 0.4799 - val_accuracy: 0.8350 - val_loss: 0.4503\n",
      "Epoch 3/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 872us/step - accuracy: 0.8482 - loss: 0.4307 - val_accuracy: 0.8450 - val_loss: 0.4235\n",
      "Epoch 4/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 989us/step - accuracy: 0.8571 - loss: 0.4022 - val_accuracy: 0.8496 - val_loss: 0.4090\n",
      "Epoch 5/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 901us/step - accuracy: 0.8650 - loss: 0.3806 - val_accuracy: 0.8532 - val_loss: 0.3962\n",
      "Epoch 6/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 890us/step - accuracy: 0.8702 - loss: 0.3634 - val_accuracy: 0.8576 - val_loss: 0.3868\n",
      "Epoch 7/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 958us/step - accuracy: 0.8747 - loss: 0.3491 - val_accuracy: 0.8596 - val_loss: 0.3822\n",
      "Epoch 8/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 919us/step - accuracy: 0.8793 - loss: 0.3375 - val_accuracy: 0.8616 - val_loss: 0.3727\n",
      "Epoch 9/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 889us/step - accuracy: 0.8831 - loss: 0.3265 - val_accuracy: 0.8624 - val_loss: 0.3706\n",
      "Epoch 10/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 886us/step - accuracy: 0.8864 - loss: 0.3170 - val_accuracy: 0.8636 - val_loss: 0.3650\n"
     ]
    }
   ],
   "source": [
    "# Neterov Optimizer\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=True)\n",
    "history_nesterov = build_and_train_model(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5775 - loss: 1.3025 - val_accuracy: 0.7822 - val_loss: 0.6708\n",
      "Epoch 2/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7827 - loss: 0.6596 - val_accuracy: 0.8084 - val_loss: 0.5740\n",
      "Epoch 3/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 952us/step - accuracy: 0.8070 - loss: 0.5790 - val_accuracy: 0.8176 - val_loss: 0.5302\n",
      "Epoch 4/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8190 - loss: 0.5389 - val_accuracy: 0.8246 - val_loss: 0.5038\n",
      "Epoch 5/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 950us/step - accuracy: 0.8264 - loss: 0.5137 - val_accuracy: 0.8312 - val_loss: 0.4861\n",
      "Epoch 6/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 941us/step - accuracy: 0.8318 - loss: 0.4963 - val_accuracy: 0.8350 - val_loss: 0.4729\n",
      "Epoch 7/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 955us/step - accuracy: 0.8364 - loss: 0.4831 - val_accuracy: 0.8400 - val_loss: 0.4628\n",
      "Epoch 8/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 984us/step - accuracy: 0.8402 - loss: 0.4727 - val_accuracy: 0.8412 - val_loss: 0.4546\n",
      "Epoch 9/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 985us/step - accuracy: 0.8425 - loss: 0.4642 - val_accuracy: 0.8422 - val_loss: 0.4477\n",
      "Epoch 10/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 999us/step - accuracy: 0.8452 - loss: 0.4570 - val_accuracy: 0.8438 - val_loss: 0.4419\n"
     ]
    }
   ],
   "source": [
    "# AdaGrad OPtimizer\n",
    "optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.001)\n",
    "history_ada_grad = build_and_train_model(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7626 - loss: 0.6627 - val_accuracy: 0.8442 - val_loss: 0.4327\n",
      "Epoch 2/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8564 - loss: 0.4006 - val_accuracy: 0.8550 - val_loss: 0.3965\n",
      "Epoch 3/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8705 - loss: 0.3689 - val_accuracy: 0.8588 - val_loss: 0.4083\n",
      "Epoch 4/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 986us/step - accuracy: 0.8748 - loss: 0.3559 - val_accuracy: 0.8550 - val_loss: 0.4371\n",
      "Epoch 5/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 983us/step - accuracy: 0.8786 - loss: 0.3475 - val_accuracy: 0.8558 - val_loss: 0.4467\n",
      "Epoch 6/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 961us/step - accuracy: 0.8799 - loss: 0.3445 - val_accuracy: 0.8442 - val_loss: 0.5449\n",
      "Epoch 7/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 997us/step - accuracy: 0.8823 - loss: 0.3438 - val_accuracy: 0.8580 - val_loss: 0.4730\n",
      "Epoch 8/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8835 - loss: 0.3434 - val_accuracy: 0.8730 - val_loss: 0.4049\n",
      "Epoch 9/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 964us/step - accuracy: 0.8857 - loss: 0.3421 - val_accuracy: 0.8696 - val_loss: 0.4379\n",
      "Epoch 10/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8860 - loss: 0.3390 - val_accuracy: 0.8536 - val_loss: 0.5263\n"
     ]
    }
   ],
   "source": [
    "# RMSProp\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
    "history_rms = build_and_train_model(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7739 - loss: 0.6320 - val_accuracy: 0.8268 - val_loss: 0.4286\n",
      "Epoch 2/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8577 - loss: 0.3919 - val_accuracy: 0.8420 - val_loss: 0.4055\n",
      "Epoch 3/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8721 - loss: 0.3468 - val_accuracy: 0.8440 - val_loss: 0.4070\n",
      "Epoch 4/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8840 - loss: 0.3170 - val_accuracy: 0.8570 - val_loss: 0.3690\n",
      "Epoch 5/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8922 - loss: 0.2959 - val_accuracy: 0.8666 - val_loss: 0.3703\n",
      "Epoch 6/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8961 - loss: 0.2793 - val_accuracy: 0.8710 - val_loss: 0.3557\n",
      "Epoch 7/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8993 - loss: 0.2677 - val_accuracy: 0.8726 - val_loss: 0.3552\n",
      "Epoch 8/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9041 - loss: 0.2545 - val_accuracy: 0.8756 - val_loss: 0.3596\n",
      "Epoch 9/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9060 - loss: 0.2474 - val_accuracy: 0.8758 - val_loss: 0.3527\n",
      "Epoch 10/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9106 - loss: 0.2342 - val_accuracy: 0.8730 - val_loss: 0.3680\n"
     ]
    }
   ],
   "source": [
    "# Adam optimizers\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "history_adam = build_and_train_model(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7736 - loss: 0.6421 - val_accuracy: 0.8398 - val_loss: 0.4102\n",
      "Epoch 2/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8598 - loss: 0.3847 - val_accuracy: 0.8434 - val_loss: 0.4117\n",
      "Epoch 3/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8735 - loss: 0.3425 - val_accuracy: 0.8518 - val_loss: 0.3955\n",
      "Epoch 4/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8833 - loss: 0.3143 - val_accuracy: 0.8492 - val_loss: 0.4035\n",
      "Epoch 5/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8917 - loss: 0.2948 - val_accuracy: 0.8622 - val_loss: 0.3898\n",
      "Epoch 6/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8985 - loss: 0.2774 - val_accuracy: 0.8598 - val_loss: 0.4056\n",
      "Epoch 7/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9008 - loss: 0.2664 - val_accuracy: 0.8684 - val_loss: 0.3805\n",
      "Epoch 8/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9045 - loss: 0.2552 - val_accuracy: 0.8612 - val_loss: 0.4049\n",
      "Epoch 9/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9081 - loss: 0.2478 - val_accuracy: 0.8710 - val_loss: 0.3909\n",
      "Epoch 10/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9114 - loss: 0.2362 - val_accuracy: 0.8712 - val_loss: 0.4041\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adamax(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "optimizer = tf.keras.optimizers.AdamW(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "history_adamw = build_and_train_model(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 866us/step - accuracy: 0.6864 - loss: 0.9502 - val_accuracy: 0.8288 - val_loss: 0.4913\n",
      "Epoch 2/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795us/step - accuracy: 0.8270 - loss: 0.4894 - val_accuracy: 0.8390 - val_loss: 0.4487\n",
      "Epoch 3/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - accuracy: 0.8453 - loss: 0.4364 - val_accuracy: 0.8448 - val_loss: 0.4285\n",
      "Epoch 4/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step - accuracy: 0.8563 - loss: 0.4068 - val_accuracy: 0.8502 - val_loss: 0.4135\n",
      "Epoch 5/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762us/step - accuracy: 0.8631 - loss: 0.3872 - val_accuracy: 0.8566 - val_loss: 0.4021\n",
      "Epoch 6/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 870us/step - accuracy: 0.8677 - loss: 0.3726 - val_accuracy: 0.8608 - val_loss: 0.3917\n",
      "Epoch 7/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 982us/step - accuracy: 0.8714 - loss: 0.3610 - val_accuracy: 0.8618 - val_loss: 0.3839\n",
      "Epoch 8/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 0.8749 - loss: 0.3514 - val_accuracy: 0.8642 - val_loss: 0.3777\n",
      "Epoch 9/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 0.8777 - loss: 0.3433 - val_accuracy: 0.8646 - val_loss: 0.3730\n",
      "Epoch 10/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 778us/step - accuracy: 0.8801 - loss: 0.3365 - val_accuracy: 0.8650 - val_loss: 0.3687\n"
     ]
    }
   ],
   "source": [
    "# Learning Scheduling\n",
    "# Power Scheduling\n",
    "\n",
    "lr_schdeule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "    initial_learning_rate=0.01, decay_steps=10_000, decay_rate=1.0, staircase=False\n",
    ")\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schdeule)\n",
    "history_power_scheduling = build_and_train_model(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 835us/step - accuracy: 0.6757 - loss: 0.9730 - val_accuracy: 0.8266 - val_loss: 0.4951\n",
      "Epoch 2/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 831us/step - accuracy: 0.8277 - loss: 0.4921 - val_accuracy: 0.8394 - val_loss: 0.4495\n",
      "Epoch 3/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816us/step - accuracy: 0.8447 - loss: 0.4402 - val_accuracy: 0.8470 - val_loss: 0.4274\n",
      "Epoch 4/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 777us/step - accuracy: 0.8558 - loss: 0.4120 - val_accuracy: 0.8516 - val_loss: 0.4098\n",
      "Epoch 5/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 789us/step - accuracy: 0.8624 - loss: 0.3934 - val_accuracy: 0.8568 - val_loss: 0.3983\n",
      "Epoch 6/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 779us/step - accuracy: 0.8658 - loss: 0.3800 - val_accuracy: 0.8602 - val_loss: 0.3894\n",
      "Epoch 7/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 0.8693 - loss: 0.3697 - val_accuracy: 0.8648 - val_loss: 0.3818\n",
      "Epoch 8/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 0.8719 - loss: 0.3619 - val_accuracy: 0.8666 - val_loss: 0.3760\n",
      "Epoch 9/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 0.8741 - loss: 0.3556 - val_accuracy: 0.8684 - val_loss: 0.3715\n",
      "Epoch 10/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 0.8757 - loss: 0.3506 - val_accuracy: 0.8696 - val_loss: 0.3679\n"
     ]
    }
   ],
   "source": [
    "# exponential Scheduling\n",
    "# learning_rate = initial_learning_rate * decay_rate ** (step/ decay_steps)\n",
    "\n",
    "lr_schdeule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.01, decay_steps=20_000, decay_rate=0.1, staircase=False\n",
    ")\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schdeule)\n",
    "history_exponential_scheduling = build_and_train_model(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom scheduling callbacks\n",
    "\n",
    "\n",
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1 ** (epoch / s)\n",
    "\n",
    "    return exponential_decay_fn\n",
    "\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 834us/step - accuracy: 0.6915 - loss: 0.9541 - val_accuracy: 0.8256 - val_loss: 0.4851 - learning_rate: 0.0100\n",
      "Epoch 2/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763us/step - accuracy: 0.8302 - loss: 0.4862 - val_accuracy: 0.8426 - val_loss: 0.4423 - learning_rate: 0.0089\n",
      "Epoch 3/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 751us/step - accuracy: 0.8472 - loss: 0.4337 - val_accuracy: 0.8484 - val_loss: 0.4234 - learning_rate: 0.0079\n",
      "Epoch 4/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 769us/step - accuracy: 0.8573 - loss: 0.4037 - val_accuracy: 0.8514 - val_loss: 0.4119 - learning_rate: 0.0071\n",
      "Epoch 5/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795us/step - accuracy: 0.8638 - loss: 0.3830 - val_accuracy: 0.8574 - val_loss: 0.4011 - learning_rate: 0.0063\n",
      "Epoch 6/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 902us/step - accuracy: 0.8684 - loss: 0.3672 - val_accuracy: 0.8572 - val_loss: 0.3918 - learning_rate: 0.0056\n",
      "Epoch 7/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843us/step - accuracy: 0.8729 - loss: 0.3549 - val_accuracy: 0.8592 - val_loss: 0.3838 - learning_rate: 0.0050\n",
      "Epoch 8/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 775us/step - accuracy: 0.8768 - loss: 0.3448 - val_accuracy: 0.8614 - val_loss: 0.3750 - learning_rate: 0.0045\n",
      "Epoch 9/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 799us/step - accuracy: 0.8800 - loss: 0.3365 - val_accuracy: 0.8640 - val_loss: 0.3683 - learning_rate: 0.0040\n",
      "Epoch 10/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816us/step - accuracy: 0.8825 - loss: 0.3295 - val_accuracy: 0.8660 - val_loss: 0.3637 - learning_rate: 0.0035\n",
      "Epoch 11/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - accuracy: 0.8853 - loss: 0.3236 - val_accuracy: 0.8688 - val_loss: 0.3585 - learning_rate: 0.0032\n",
      "Epoch 12/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 746us/step - accuracy: 0.8865 - loss: 0.3184 - val_accuracy: 0.8698 - val_loss: 0.3543 - learning_rate: 0.0028\n",
      "Epoch 13/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 788us/step - accuracy: 0.8877 - loss: 0.3140 - val_accuracy: 0.8714 - val_loss: 0.3511 - learning_rate: 0.0025\n",
      "Epoch 14/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 810us/step - accuracy: 0.8887 - loss: 0.3102 - val_accuracy: 0.8720 - val_loss: 0.3483 - learning_rate: 0.0022\n",
      "Epoch 15/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853us/step - accuracy: 0.8897 - loss: 0.3067 - val_accuracy: 0.8736 - val_loss: 0.3458 - learning_rate: 0.0020\n",
      "Epoch 16/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 797us/step - accuracy: 0.8907 - loss: 0.3037 - val_accuracy: 0.8738 - val_loss: 0.3440 - learning_rate: 0.0018\n",
      "Epoch 17/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - accuracy: 0.8915 - loss: 0.3010 - val_accuracy: 0.8752 - val_loss: 0.3424 - learning_rate: 0.0016\n",
      "Epoch 18/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.8928 - loss: 0.2987 - val_accuracy: 0.8760 - val_loss: 0.3411 - learning_rate: 0.0014\n",
      "Epoch 19/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741us/step - accuracy: 0.8931 - loss: 0.2966 - val_accuracy: 0.8748 - val_loss: 0.3399 - learning_rate: 0.0013\n",
      "Epoch 20/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 758us/step - accuracy: 0.8942 - loss: 0.2948 - val_accuracy: 0.8758 - val_loss: 0.3387 - learning_rate: 0.0011\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = build_model()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "n_epochs = 20\n",
    "lr_schduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=n_epochs,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[lr_schduler],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = tf.keras.backend\n",
    "\n",
    "\n",
    "class ExponentialDecay(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, n_steps=40000):\n",
    "        super().__init__()\n",
    "        self.n_steps = n_steps\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        # Note: the `batch` argument is reset at each epoch\n",
    "        lr = self.model.optimizer.learning_rate.numpy()\n",
    "        new_leatning_rate = lr * 0.1 ** (1 / self.n_steps)\n",
    "        self.model.optimizer.learning_rate = new_leatning_rate\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs[\"lr\"] = self.model.optimizer.learning_rate.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr0 = 0.01\n",
    "model = build_model()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr0)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6865 - loss: 0.9407 - val_accuracy: 0.8274 - val_loss: 0.4930 - lr: 0.0089\n",
      "Epoch 2/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 960us/step - accuracy: 0.8293 - loss: 0.4873 - val_accuracy: 0.8418 - val_loss: 0.4523 - lr: 0.0079\n",
      "Epoch 3/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 961us/step - accuracy: 0.8475 - loss: 0.4363 - val_accuracy: 0.8472 - val_loss: 0.4330 - lr: 0.0071\n",
      "Epoch 4/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 959us/step - accuracy: 0.8573 - loss: 0.4080 - val_accuracy: 0.8484 - val_loss: 0.4239 - lr: 0.0063\n",
      "Epoch 5/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 972us/step - accuracy: 0.8627 - loss: 0.3887 - val_accuracy: 0.8510 - val_loss: 0.4164 - lr: 0.0056\n",
      "Epoch 6/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 957us/step - accuracy: 0.8683 - loss: 0.3740 - val_accuracy: 0.8540 - val_loss: 0.4069 - lr: 0.0050\n",
      "Epoch 7/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 959us/step - accuracy: 0.8719 - loss: 0.3621 - val_accuracy: 0.8560 - val_loss: 0.4002 - lr: 0.0045\n",
      "Epoch 8/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 961us/step - accuracy: 0.8745 - loss: 0.3523 - val_accuracy: 0.8614 - val_loss: 0.3914 - lr: 0.0040\n",
      "Epoch 9/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 969us/step - accuracy: 0.8777 - loss: 0.3440 - val_accuracy: 0.8622 - val_loss: 0.3832 - lr: 0.0035\n",
      "Epoch 10/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 966us/step - accuracy: 0.8797 - loss: 0.3371 - val_accuracy: 0.8636 - val_loss: 0.3771 - lr: 0.0032\n",
      "Epoch 11/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 957us/step - accuracy: 0.8821 - loss: 0.3312 - val_accuracy: 0.8664 - val_loss: 0.3728 - lr: 0.0028\n",
      "Epoch 12/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 969us/step - accuracy: 0.8837 - loss: 0.3261 - val_accuracy: 0.8674 - val_loss: 0.3686 - lr: 0.0025\n",
      "Epoch 13/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 952us/step - accuracy: 0.8855 - loss: 0.3216 - val_accuracy: 0.8694 - val_loss: 0.3648 - lr: 0.0022\n",
      "Epoch 14/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 964us/step - accuracy: 0.8867 - loss: 0.3177 - val_accuracy: 0.8698 - val_loss: 0.3613 - lr: 0.0020\n",
      "Epoch 15/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 979us/step - accuracy: 0.8880 - loss: 0.3143 - val_accuracy: 0.8702 - val_loss: 0.3582 - lr: 0.0018\n",
      "Epoch 16/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 970us/step - accuracy: 0.8888 - loss: 0.3112 - val_accuracy: 0.8710 - val_loss: 0.3559 - lr: 0.0016\n",
      "Epoch 17/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 962us/step - accuracy: 0.8895 - loss: 0.3086 - val_accuracy: 0.8730 - val_loss: 0.3538 - lr: 0.0014\n",
      "Epoch 18/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 986us/step - accuracy: 0.8904 - loss: 0.3063 - val_accuracy: 0.8738 - val_loss: 0.3520 - lr: 0.0013\n",
      "Epoch 19/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 981us/step - accuracy: 0.8910 - loss: 0.3043 - val_accuracy: 0.8746 - val_loss: 0.3505 - lr: 0.0011\n",
      "Epoch 20/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 976us/step - accuracy: 0.8914 - loss: 0.3024 - val_accuracy: 0.8748 - val_loss: 0.3490 - lr: 1.0000e-03\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "n_steps = n_epochs * math.ceil(len(X_train) / batch_size)\n",
    "exp_decay = ExponentialDecay(n_steps)\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=n_epochs,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[exp_decay],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 863us/step - accuracy: 0.6684 - loss: 0.9834 - val_accuracy: 0.8306 - val_loss: 0.4933\n",
      "Epoch 2/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 775us/step - accuracy: 0.8253 - loss: 0.5006 - val_accuracy: 0.8396 - val_loss: 0.4439\n",
      "Epoch 3/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 769us/step - accuracy: 0.8451 - loss: 0.4466 - val_accuracy: 0.8454 - val_loss: 0.4220\n",
      "Epoch 4/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 776us/step - accuracy: 0.8557 - loss: 0.4179 - val_accuracy: 0.8510 - val_loss: 0.4088\n",
      "Epoch 5/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 788us/step - accuracy: 0.8618 - loss: 0.3990 - val_accuracy: 0.8566 - val_loss: 0.3985\n",
      "Epoch 6/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 790us/step - accuracy: 0.8655 - loss: 0.3855 - val_accuracy: 0.8588 - val_loss: 0.3901\n",
      "Epoch 7/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 785us/step - accuracy: 0.8696 - loss: 0.3753 - val_accuracy: 0.8620 - val_loss: 0.3820\n",
      "Epoch 8/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 778us/step - accuracy: 0.8729 - loss: 0.3673 - val_accuracy: 0.8638 - val_loss: 0.3764\n",
      "Epoch 9/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 777us/step - accuracy: 0.8747 - loss: 0.3610 - val_accuracy: 0.8658 - val_loss: 0.3713\n",
      "Epoch 10/10\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780us/step - accuracy: 0.8762 - loss: 0.3561 - val_accuracy: 0.8674 - val_loss: 0.3677\n"
     ]
    }
   ],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries=[50_000, 80_000], values=[0.01, 0.005, 0.001]\n",
    ")\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schdeule)\n",
    "history_piecewise_scheduling = build_and_train_model(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance Scheduling\n",
    "model = build_model()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr0)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 835us/step - accuracy: 0.6724 - loss: 0.9592 - val_accuracy: 0.8290 - val_loss: 0.4922 - learning_rate: 0.0100\n",
      "Epoch 2/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step - accuracy: 0.8270 - loss: 0.4896 - val_accuracy: 0.8386 - val_loss: 0.4477 - learning_rate: 0.0089\n",
      "Epoch 3/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 785us/step - accuracy: 0.8481 - loss: 0.4341 - val_accuracy: 0.8490 - val_loss: 0.4269 - learning_rate: 0.0079\n",
      "Epoch 4/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 0.8588 - loss: 0.4035 - val_accuracy: 0.8514 - val_loss: 0.4108 - learning_rate: 0.0071\n",
      "Epoch 5/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - accuracy: 0.8663 - loss: 0.3832 - val_accuracy: 0.8566 - val_loss: 0.3978 - learning_rate: 0.0063\n",
      "Epoch 6/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 788us/step - accuracy: 0.8712 - loss: 0.3679 - val_accuracy: 0.8584 - val_loss: 0.3903 - learning_rate: 0.0056\n",
      "Epoch 7/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 767us/step - accuracy: 0.8751 - loss: 0.3558 - val_accuracy: 0.8632 - val_loss: 0.3819 - learning_rate: 0.0050\n",
      "Epoch 8/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - accuracy: 0.8775 - loss: 0.3458 - val_accuracy: 0.8648 - val_loss: 0.3757 - learning_rate: 0.0045\n",
      "Epoch 9/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762us/step - accuracy: 0.8807 - loss: 0.3373 - val_accuracy: 0.8652 - val_loss: 0.3705 - learning_rate: 0.0040\n",
      "Epoch 10/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763us/step - accuracy: 0.8836 - loss: 0.3300 - val_accuracy: 0.8670 - val_loss: 0.3662 - learning_rate: 0.0035\n",
      "Epoch 11/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 789us/step - accuracy: 0.8855 - loss: 0.3239 - val_accuracy: 0.8686 - val_loss: 0.3618 - learning_rate: 0.0032\n",
      "Epoch 12/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 776us/step - accuracy: 0.8876 - loss: 0.3185 - val_accuracy: 0.8694 - val_loss: 0.3585 - learning_rate: 0.0028\n",
      "Epoch 13/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 0.8895 - loss: 0.3139 - val_accuracy: 0.8682 - val_loss: 0.3556 - learning_rate: 0.0025\n",
      "Epoch 14/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795us/step - accuracy: 0.8910 - loss: 0.3097 - val_accuracy: 0.8692 - val_loss: 0.3527 - learning_rate: 0.0022\n",
      "Epoch 15/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - accuracy: 0.8920 - loss: 0.3061 - val_accuracy: 0.8700 - val_loss: 0.3502 - learning_rate: 0.0020\n",
      "Epoch 16/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 775us/step - accuracy: 0.8929 - loss: 0.3030 - val_accuracy: 0.8700 - val_loss: 0.3479 - learning_rate: 0.0018\n",
      "Epoch 17/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - accuracy: 0.8934 - loss: 0.3002 - val_accuracy: 0.8710 - val_loss: 0.3461 - learning_rate: 0.0016\n",
      "Epoch 18/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 769us/step - accuracy: 0.8943 - loss: 0.2977 - val_accuracy: 0.8714 - val_loss: 0.3443 - learning_rate: 0.0014\n",
      "Epoch 19/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 785us/step - accuracy: 0.8947 - loss: 0.2956 - val_accuracy: 0.8728 - val_loss: 0.3428 - learning_rate: 0.0013\n",
      "Epoch 20/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 789us/step - accuracy: 0.8955 - loss: 0.2937 - val_accuracy: 0.8730 - val_loss: 0.3411 - learning_rate: 0.0011\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "history_performance_scheduler = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=n_epochs,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[lr_schduler],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(tf.keras.callbacks.Callback):\n",
    "    def __init__(\n",
    "        self, iterations, max_lr=1e-3, start_lr=None, last_iterations=None, last_lr=None\n",
    "    ):\n",
    "        self.iterations = iterations\n",
    "        self.max_lr = max_lr\n",
    "        self.start_lr = start_lr or max_lr / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_lr = last_lr or self.start_lr / 1000\n",
    "        self.iteration = 0\n",
    "\n",
    "    def _interpolate(self, iter1, iter2, lr1, lr2):\n",
    "        return (lr2 - lr1) * (self.iteration - iter1) / (iter2 - iter1) + lr1\n",
    "\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            lr = self._interpolate(0, self.half_iteration, self.start_lr, self.max_lr)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            lr = self._interpolate(\n",
    "                self.half_iteration, 2 * self.half_iteration, self.max_lr, self.start_lr\n",
    "            )\n",
    "        else:\n",
    "            lr = self._interpolate(\n",
    "                2 * self.half_iteration, self.iterations, self.start_lr, self.last_lr\n",
    "            )\n",
    "        self.iteration += 1\n",
    "        self.model.optimizer.learning_rate = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 993us/step - accuracy: 0.6824 - loss: 0.9495 - val_accuracy: 0.8184 - val_loss: 0.5158\n",
      "Epoch 2/25\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 908us/step - accuracy: 0.8321 - loss: 0.4795 - val_accuracy: 0.8206 - val_loss: 0.4938\n",
      "Epoch 3/25\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 893us/step - accuracy: 0.8491 - loss: 0.4178 - val_accuracy: 0.8284 - val_loss: 0.4723\n",
      "Epoch 4/25\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 914us/step - accuracy: 0.8612 - loss: 0.3847 - val_accuracy: 0.8455 - val_loss: 0.4252\n",
      "Epoch 5/25\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 905us/step - accuracy: 0.8675 - loss: 0.3632 - val_accuracy: 0.8465 - val_loss: 0.4218\n",
      "Epoch 6/25\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 915us/step - accuracy: 0.8733 - loss: 0.3439 - val_accuracy: 0.8459 - val_loss: 0.4206\n",
      "Epoch 7/25\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 912us/step - accuracy: 0.8791 - loss: 0.3279 - val_accuracy: 0.8510 - val_loss: 0.4161\n",
      "Epoch 8/25\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 908us/step - accuracy: 0.8832 - loss: 0.3174 - val_accuracy: 0.8583 - val_loss: 0.3943\n",
      "Epoch 9/25\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 907us/step - accuracy: 0.8854 - loss: 0.3046 - val_accuracy: 0.8611 - val_loss: 0.3970\n",
      "Epoch 10/25\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 929us/step - accuracy: 0.8886 - loss: 0.2987 - val_accuracy: 0.7997 - val_loss: 0.6512\n",
      "Epoch 11/25\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 913us/step - accuracy: 0.8914 - loss: 0.2941 - val_accuracy: 0.8675 - val_loss: 0.3782\n",
      "Epoch 12/25\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 909us/step - accuracy: 0.8941 - loss: 0.2819 - val_accuracy: 0.8634 - val_loss: 0.4077\n",
      "Epoch 13/25\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 912us/step - accuracy: 0.9013 - loss: 0.2677 - val_accuracy: 0.8705 - val_loss: 0.3768\n",
      "Epoch 14/25\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 909us/step - accuracy: 0.9071 - loss: 0.2464 - val_accuracy: 0.8523 - val_loss: 0.4514\n",
      "Epoch 15/25\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 932us/step - accuracy: 0.9122 - loss: 0.2326 - val_accuracy: 0.8719 - val_loss: 0.3820\n",
      "Epoch 16/25\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 909us/step - accuracy: 0.9188 - loss: 0.2167 - val_accuracy: 0.8727 - val_loss: 0.3796\n",
      "Epoch 17/25\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 914us/step - accuracy: 0.9237 - loss: 0.2041 - val_accuracy: 0.8775 - val_loss: 0.3706\n",
      "Epoch 18/25\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 914us/step - accuracy: 0.9273 - loss: 0.1929 - val_accuracy: 0.8782 - val_loss: 0.3759\n",
      "Epoch 19/25\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 919us/step - accuracy: 0.9321 - loss: 0.1814 - val_accuracy: 0.8778 - val_loss: 0.3781\n",
      "Epoch 20/25\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 925us/step - accuracy: 0.9359 - loss: 0.1724 - val_accuracy: 0.8821 - val_loss: 0.3741\n",
      "Epoch 21/25\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 911us/step - accuracy: 0.9386 - loss: 0.1648 - val_accuracy: 0.8797 - val_loss: 0.3708\n",
      "Epoch 22/25\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 955us/step - accuracy: 0.9410 - loss: 0.1582 - val_accuracy: 0.8846 - val_loss: 0.3606\n",
      "Epoch 23/25\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 921us/step - accuracy: 0.9424 - loss: 0.1541 - val_accuracy: 0.8866 - val_loss: 0.3530\n",
      "Epoch 24/25\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 914us/step - accuracy: 0.9442 - loss: 0.1515 - val_accuracy: 0.8894 - val_loss: 0.3492\n",
      "Epoch 25/25\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 916us/step - accuracy: 0.9439 - loss: 0.1504 - val_accuracy: 0.8910 - val_loss: 0.3473\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "n_epochs = 25\n",
    "onecycle = OneCycleScheduler(\n",
    "    math.ceil(len(X_train) / batch_size) * n_epochs, max_lr=0.1\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=n_epochs,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[onecycle],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoiding Overfittin through regularization\n",
    "RegularDenselayer = partial(\n",
    "    tf.keras.layers.Dense,\n",
    "    activation=\"relu\",\n",
    "    kernel_initializer=\"he_normal\",\n",
    "    kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    ")\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Input(shape=(28, 28)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        RegularDenselayer(100),\n",
    "        RegularDenselayer(100),\n",
    "        RegularDenselayer(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 812us/step - accuracy: 0.7088 - loss: 4.0575 - val_accuracy: 0.8220 - val_loss: 1.8543\n",
      "Epoch 2/2\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 752us/step - accuracy: 0.8134 - loss: 1.6180 - val_accuracy: 0.8256 - val_loss: 1.1174\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.02)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model.fit(X_train, y_train, epochs=2, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
