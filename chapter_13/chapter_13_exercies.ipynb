{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.train import Feature, Features, Example, BytesList, Int64List\n",
    "from contextlib import ExitStack\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = (\n",
    "    tf.keras.datasets.fashion_mnist.load_data()\n",
    ")\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating training tf sets\n",
    "train_set = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_set = train_set.shuffle(len(X_train), seed=42)\n",
    "valid_set = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n",
    "test_set = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example(image, label):\n",
    "\n",
    "    image_data = tf.io.serialize_tensor(image)\n",
    "\n",
    "    return Example(\n",
    "        features=Features(\n",
    "            feature={\n",
    "                \"image\": Feature(bytes_list=BytesList(value=[image_data.numpy()])),\n",
    "                \"label\": Feature(int64_list=Int64List(value=[label])),\n",
    "            }\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tfrecords(name, dataset, n_shards=10):\n",
    "    paths = [\n",
    "        \"{}.tfrecord-{:05d}-of-{:05d}\".format(name, index + 1, n_shards)\n",
    "        for index in range(n_shards)\n",
    "    ]\n",
    "    with ExitStack() as stack:\n",
    "        writers = [stack.enter_context(tf.io.TFRecordWriter(path)) for path in paths]\n",
    "\n",
    "        for index, (image, label) in dataset.enumerate():\n",
    "            shard = index % n_shards\n",
    "            example = create_example(image, label)\n",
    "            writers[shard].write(example.SerializeToString())\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 21:37:26.504327: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "train_filepaths = write_tfrecords(\"my_fashion_mnist.train\", train_set)\n",
    "valid_filepaths = write_tfrecords(\"my_fashion_mnist.valid\", valid_set)\n",
    "test_filepaths = write_tfrecords(\"my_fashion_mnist.test\", test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tfrecord):\n",
    "    feature_dict = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64, default_value=-1),\n",
    "    }\n",
    "\n",
    "    example = tf.io.parse_single_example(tfrecord, feature_dict)\n",
    "    image = tf.io.parse_tensor(example[\"image\"], out_type=tf.uint8)\n",
    "    # image = tf.io.decode_jpeg(example[\"image\"])\n",
    "    image = tf.reshape(image, shape=[28, 28])\n",
    "    return image, example[\"label\"]\n",
    "\n",
    "\n",
    "def mnist_dataset(\n",
    "    filepaths,\n",
    "    n_read_threads=5,\n",
    "    shuffle_buffer_size=None,\n",
    "    n_parse_threads=5,\n",
    "    batch_size=32,\n",
    "    cache=True,\n",
    "):\n",
    "    dataset = tf.data.TFRecordDataset(filepaths, num_parallel_reads=n_read_threads)\n",
    "    if cache:\n",
    "        dataset = dataset.cache()\n",
    "    if shuffle_buffer_size:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = mnist_dataset(train_filepaths)\n",
    "valid_set = mnist_dataset(valid_filepaths)\n",
    "test_set = mnist_dataset(test_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 21:53:20.900625: W tensorflow/core/kernels/data/cache_dataset_ops.cc:914] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for X, y in train_set.take(1):\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(X[i].numpy(), cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(str(y[i].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 22:16:47.702587: W tensorflow/core/kernels/data/cache_dataset_ops.cc:914] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "input_layer = tf.keras.Input(shape=(28, 28))\n",
    "standardization = tf.keras.layers.Normalization()\n",
    "sample_image_batches = train_set.take(100).map(lambda image, label: image)\n",
    "sample_images = np.concatenate(\n",
    "    list(sample_image_batches.as_numpy_iterator()), axis=0\n",
    ").astype(np.float32)\n",
    "standardization.adapt(sample_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 22:21:45.425404: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.\n",
      "2025-03-26 22:21:45.425416: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.\n",
      "2025-03-26 22:21:45.425484: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    144/Unknown \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6449 - loss: 1.0460"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 22:21:46.205751: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.\n",
      "2025-03-26 22:21:46.205770: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.\n",
      "2025-03-26 22:21:46.208534: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:68] Profiler session collecting data.\n",
      "2025-03-26 22:21:46.212072: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.\n",
      "2025-03-26 22:21:46.214158: I external/local_xla/xla/tsl/profiler/rpc/client/save_profile.cc:147] Collecting XSpace to repository: my_logs/run_/20250326_222145/train/plugins/profile/2025_03_26_22_21_46/Chirags-Mac-mini.local.xplane.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1700/Unknown \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8049 - loss: 0.5553"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chiragbangera/Developer/Handsonml/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n",
      "2025-03-26 22:21:48.688422: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8053 - loss: 0.5540 - val_accuracy: 0.8682 - val_loss: 0.3720\n",
      "Epoch 2/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8774 - loss: 0.3421 - val_accuracy: 0.8760 - val_loss: 0.3438\n",
      "Epoch 3/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8912 - loss: 0.2997 - val_accuracy: 0.8788 - val_loss: 0.3398\n",
      "Epoch 4/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8994 - loss: 0.2702 - val_accuracy: 0.8798 - val_loss: 0.3394\n",
      "Epoch 5/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9076 - loss: 0.2475 - val_accuracy: 0.8792 - val_loss: 0.3515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x31a2feb40>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        input_layer,\n",
    "        standardization,\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"]\n",
    ")\n",
    "logs = Path() / \"my_logs\" / \"run_\" / datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logs, histogram_freq=1, profile_batch=10\n",
    ")\n",
    "\n",
    "model.fit(train_set, epochs=5, validation_data=valid_set, callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
